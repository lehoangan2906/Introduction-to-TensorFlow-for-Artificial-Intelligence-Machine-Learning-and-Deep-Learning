{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Load and normalize the Fashion MNIST dataset\n",
        "\n",
        "Like the previous lab, you will use the fashion MNIST dataset again for this exercise. And also as mentioned before, you will normalize the pixel values to help optimize the training.\n"
      ],
      "metadata": {
        "id": "Eu7M4pIBi4JA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yfkk6a6Xiwru"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Instantizte the dataset API\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating callback class\n",
        "\n",
        "You can create a callback by defining a class that inherits the tf.keras.callbacks.Callback base class. From there, you can define available methods to set where the callback will be executed. For instance below, you will use the on_epoch_end() method to check the loss at training epoch"
      ],
      "metadata": {
        "id": "LQkYklMdk0M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    '''\n",
        "    Halts the training after reaching 60 percent accuracy\n",
        "\n",
        "    Args:\n",
        "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
        "      logs (dict) - metric results from the training epoch\n",
        "    '''\n",
        "\n",
        "    # Check accuracy\n",
        "    if(logs.get('loss') < 0.4):\n",
        "\n",
        "      # Stop if threshold is met\n",
        "      print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "mkkPBqfDkjNL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define and compile the model\n",
        "\n",
        "Next, you will define and compile the model. The architecture will be similar to the one you built in the previous lab. Afterwards, you will set the optimizer, loss, and metrics that you will use for training."
      ],
      "metadata": {
        "id": "xshdhx7BpYoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
        "    tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer = tf.optimizers.Adam(), \n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "8UAOizsGkzj4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model\n",
        "\n",
        "Now you are ready to train the model. To set the callback, simply set the callbacks parameter to the myCallback instanyou declared before. Run the cell below and observe what happens."
      ],
      "metadata": {
        "id": "NdCSu7cNqK_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model wit a callback\n",
        "model.fit(x_train, y_train, epochs = 10, callbacks = [callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DamDLJH5qDvm",
        "outputId": "fbbc7c98-d309-41f6-8e71-477f920c1ca4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.4738 - accuracy: 0.8306\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.3609 - accuracy: 0.8672\n",
            "Loss is lower than 0.4 so cancelling training!\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3609 - accuracy: 0.8672\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ec8870760>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will notice that the training does not need to complete all 10 epochs. By having a callback at each end of the epoch. It is able to check the training parameters and compare if it meets the threshold you set in the function definition. In this case, it will simply stop when the loss falls below 0.40 after the current epoch.\n",
        "\n"
      ],
      "metadata": {
        "id": "N_dL_V40qpC1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p63VhN4YqeC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}